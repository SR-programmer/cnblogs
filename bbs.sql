/*
 Navicat Premium Data Transfer

 Source Server         : SR
 Source Server Type    : MySQL
 Source Server Version : 50645
 Source Host           : localhost:3306
 Source Schema         : bbs

 Target Server Type    : MySQL
 Target Server Version : 50645
 File Encoding         : 65001

 Date: 12/04/2020 20:13:25
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for app01_article
-- ----------------------------
DROP TABLE IF EXISTS `app01_article`;
CREATE TABLE `app01_article`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `content` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `create_time` date NOT NULL,
  `comment_num` int(11) NOT NULL,
  `up_num` int(11) NOT NULL,
  `down_num` int(11) NOT NULL,
  `site_id` int(11) NULL DEFAULT NULL,
  `category_id` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app01_article_category_id_acb2c466_fk_app01_category_id`(`category_id`) USING BTREE,
  INDEX `app01_article_site_id_3b3d58f6_fk_app01_site_id`(`site_id`) USING BTREE,
  CONSTRAINT `app01_article_category_id_acb2c466_fk_app01_category_id` FOREIGN KEY (`category_id`) REFERENCES `app01_category` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `app01_article_site_id_3b3d58f6_fk_app01_site_id` FOREIGN KEY (`site_id`) REFERENCES `app01_site` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 19 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_article
-- ----------------------------
INSERT INTO `app01_article` VALUES (1, '在vscode中配置python环境', '1.安装vscode和python3.7（安装路径在：E:\\Python\\Python37）； 2.打开vscode，在左下角点击设置图标选择setting，搜索python path，在该路径下选择python的安装路径（E:\\Python\\Python37），如', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-09-04', 3, 2, 0, 1, 1);
INSERT INTO `app01_article` VALUES (3, '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', '目录 \"抽象类介绍\" \"为什么要用抽象类\" \"一个抽象类小故事\" \"一个抽象类小游戏\" \"接口介绍\" \"接口与类相似点：\" \"接口与类的区别：\" \"接口特性\" \"抽象类和接口的区别\" \"接口的使用：\" \"接口最佳实践：设计模式中的工厂模式\" \"接口与抽象类的本质区别是什么？\" \"基本语法区别\" \"设 ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-08-01', 0, 0, 0, 1, 1);
INSERT INTO `app01_article` VALUES (4, '品Spring：SpringBoot和Spring到底有没有本质的不同？', '现在的Spring相关开发都是基于SpringBoot的。最后在打包时可以把所有依赖的jar包都打进去，构成一个独立的可执行的jar包。如下图13： 使用java -jar命令就可以运行这个独立的jar包。如下图14： 这个jar包的执行入口就是一个main函数，典型的格式如下： 从代码中可以得知， ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-10-01', 0, 0, 0, 1, 2);
INSERT INTO `app01_article` VALUES (5, 'golang1.13中重要的新特新', '本文索引 语言变化 数字字面量 越界索引报错的完善 工具链改进 GOPROXY GOSUMDB GOPRIVATE 标准库的新功能 判断变量是否为0值 错误处理的革新 Unwrap Is As golang1.13发布已经有一个月了，本文将会列举其中几个较为重要的特性。我们将会从语言变化、库变化以及 .', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-07-08', 0, 0, 0, 1, 2);
INSERT INTO `app01_article` VALUES (6, '注解在Java中是如何工作的', '来一点咖啡，准备好进入注解的世界。 注解一直是 Java 的一个非常重要的部分，它从 J2SE 5.0 开始就已经存在了。在我们的应用程序代码中，经常看到 和 这样的注解。在本文中，我将讨论注解到底是什么，为什么引入注解，它们是如何工作的，如何编写自定义注解(有示例代码)，注解的有效场景是什么，最后 ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-07-01', 0, 0, 0, 1, 3);
INSERT INTO `app01_article` VALUES (7, 'Spring Boot 配置元数据指南', '概览 在编写 Spring Boot 应用程序时， \"将配置属性映射到 Java bean 上\" 是非常有用的。但是，记录这些属性的最好方法是什么呢？ 在本教程中，我们将探讨 \"Spring Boot Configuration Processor\" 和 \"关联的 JSON 元数据文件\"', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-11-01', 1, 1, 0, 2, 6);
INSERT INTO `app01_article` VALUES (8, 'oracle异机恢复测试', '一)问题背景 最近在生产环境中，开发人员误操作，使用truncate将oracle数据库某个表的数据全部删除了，在删除之后，开发人员发现自己闯祸了，于是联系值班的DBA进行紧急数据恢复。 经过分析，表被truncate后，使用一般的闪回表、闪回查询、闪回事物等方法，是不可能将数据找回来的，可以使用.', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2020-01-01', 0, 1, 0, 2, 7);
INSERT INTO `app01_article` VALUES (9, 'MyBatis 插件使用-自定义简单的分页插件', '@[TOC] 作为一个优秀的框架， 其除了要解决大部分的流程之外， 还需要提供给使用者能够自定义的能力。 有缓存， 有插件接口等。我们可以通过自定义插件的方式来对 进行使用上的扩展。 以一个简单的 mysql 分页插件为例， 插件的使用包含以下步骤： 1 分页参数的传递 分页参数就是 offset ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-05-01', 1, 1, 0, 2, 7);
INSERT INTO `app01_article` VALUES (10, '代码不规范，同事皮锤现（上）', '没错，在下就是传说中的标题党本党了，可能大家对这个标题都有所理解，now，我们来设想一个情景，当你的老大让你去修改别人的代码时，当你怀着热切的心情打开代码定睛一瞧，缩进错乱，命名不规范，通篇没注释，你是不是有那木一刻非常想提起四十米的大刀大喊一声：狗贼，来吃洒家一刀!!! 为了防止世界被破坏，为了守 ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-04-03', 0, 0, 0, 2, 8);
INSERT INTO `app01_article` VALUES (11, '数据结构之二叉树篇卷三 -- 二叉树非递归遍历（With Java)', 'Nonrecursive Traversal of Binary Tree First I wanna talk about why should we use <code>Stack</code> to implement this algorithm. I think it is due to ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2020-03-27', 0, 0, 0, 3, 4);
INSERT INTO `app01_article` VALUES (12, '什么样的代码是好代码？', '关于什么是好代码，软件行业烂大街的名词一大堆，什么高内聚、低耦合、可复用、可扩展、健壮性等等。也有所谓设计6原则—SOLID: 即Single Responsibility （单一职责），Open Close（开闭），Liskov Substitution（里氏替换），Interface Segre ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-04-29', 0, 0, 0, 3, 4);
INSERT INTO `app01_article` VALUES (13, 'linux系统下开发环境安装与配置', '安装系统环境 CentOS 6.8 64位 jdk版本 7u80 64位 Tomcat版本 Tomcat7 maven版本 Apache Maven 3.6.0 vsftpd版本 vsftpd 2.2.2 24.el6.x86_64 Nginx版本 nginx 1.14.2 mysql版本 mysq ...', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2010-05-01', 18, 1, 0, 3, 5);
INSERT INTO `app01_article` VALUES (14, 'python基础', '博客目录 python基础部分 基础 计算机硬件发展史 计算机硬件 python入门 数据类型及常用方法 字符编码 文件处理 函数 初识函数 函数进阶 装饰器函数 迭代器和生成器 内置函数和匿名函数 递归函数 常用模块 常用模块 模块和包 面向对象 初识面向对象 面向对象进阶 网络编程 网络编程 并', 'Django框架\r\n前言\r\n\r\n2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。\r\n\r\n不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。\r\n\r\n \r\n\r\ntop命令\r\n\r\n既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。\r\n\r\ntop命令是最常见的查看cpu和load的命令，拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：\r\n\r\n\r\n\r\n做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：\r\n\r\n\r\n\r\n内存与SWAP输出格式是一样的，因此放在了一起写。\r\n\r\n \r\n\r\ncpu如何计算\r\n\r\n当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。\r\n\r\ncpu分为系统cpu和进程、线程cpu，系统cpu的统计值位于/proc/stat下（以下的截图未截全）：\r\n\r\n\r\n\r\ncpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。\r\n\r\n进程cpu的统计值位于/proc/{pid}/stat下：\r\n\r\n\r\n\r\n线程cpu的统计值位于/proc/{pid}/task/{threadId}/stat下： \r\n\r\n \r\n\r\n这里面的所有值都是从系统启动时间到当前时间的一个值。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：\r\n\r\n将t1的所有cpu使用情况求和，得到s1\r\n将t2的所有cpu使用情况求和，得到s2\r\ns2 - s1得到这个时间间隔内的所有时间totalCpuTime\r\n第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间\r\ncpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime\r\n其他时间例如us、sy、ni都是类似的计算方式，总结起来说，cpu这个值反应的是某个采样时间内的cpu使用情况。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。\r\n\r\n假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。\r\n\r\n \r\n\r\n对load的理解\r\n\r\n关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：\r\n\r\n复制代码\r\n一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。\r\n如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于0.00，表示目前桥面上没有任何的车流。实际上这种情况0.00和1.00之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于1.00，表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如2.00的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待\r\n复制代码\r\n但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：\r\n\r\n\r\n\r\n大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示正在使用cpu或者等待使用cpu，一个不可中断状态的进程表示正在等待IO，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。\r\n\r\n特别注意，load指的是所有核的平均值，这和cpu的值是有区别的。\r\n\r\n还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是进程中的线程数也是会被当作不同的进程来计算的，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。\r\n\r\n \r\n\r\n请求数和load的关系\r\n\r\n之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。\r\n\r\n以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f）：\r\n\r\n\r\n\r\n单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。\r\n\r\n整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是工作线程数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，load是以线程/进程作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。\r\n\r\n举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：\r\n\r\n正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低\r\n某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）\r\n因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。', '2019-09-28', 0, 0, 0, 4, 9);
INSERT INTO `app01_article` VALUES (15, 'Django框架', '第一篇: Django简介 第二篇: 路由控制 第三篇: 视图层 第四篇: 模版层 第五篇: 1.ORM常用字段及参数 2.F与Q查询,事务及其他 第六篇: 1.Django与Ajax 2.分页器组件 3.form组件 4.Cookie与Session组件 5.中间件 6.Auth认证模块 7.Co 阅读全文', '<div id=\"cnblogs_post_body\" class=\"blogpost-body \">\r\n    <p><strong><span style=\"font-size: 18px; font-family: \'Microsoft YaHei\';\">前言</span></strong></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">2019双11还有不到2个月就要到来了，大家也都知道服务器在大促期间由于流量的增加势必导致机器的cpu与load变高。</span><span style=\"font-size: 14px; font-family: 宋体;\">因此趁着这个时机正好再好好学习、巩固一下cpu和load的概念，为双11做准备的同时也是增加自己的技能储备。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">不过cpu和load这块真的还是很需要积累的，我自己经验尚浅，感觉还是有许多写的不到位与不对的地方，也是希望如果有错误，大家可以帮助指正。</span></p>\r\n<p>&nbsp;</p>\r\n<p><strong><span style=\"font-size: 18px; font-family: \'Microsoft YaHei\';\">top命令</span></strong></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">既然说了cpu和load，那总需要监控吧，没有监控就不知道cpu和load，后面的一切也就无从谈起了。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">top命令是最常见的查看cpu和load的命令，</span><span style=\"font-size: 14px; font-family: 宋体;\">拿我自己虚拟机上装的ubuntu系统执行一下top命令（默认3秒刷1次，-d可指定刷新时间）：</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201906/801753-20190619112115464-1159095756.png\" alt=\"\" width=\"602\" height=\"188\"></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">做了一张表格比较详细地解释了每一部分的含义，其中重要属性做了标红加粗：</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201909/801753-20190928153957669-97998610.png\" alt=\"\"></span></p>\r\n<p><span style=\"font-family: 宋体;\">内存与SWAP输出格式是一样的，因此放在了一起写。</span></p>\r\n<p>&nbsp;</p>\r\n<p><strong><span style=\"font-size: 18px; font-family: \'Microsoft YaHei\';\">cpu如何计算</span></strong></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">当我们执行top命令的时候，看到里面的值（主要是cpu和load）值是一直在变的，因此有必要简单了解一下Linux系统中cpu的计算方式。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">cpu分为系统cpu和进程、线程cpu，<span style=\"color: #000000;\">系统cpu</span>的统计值位于<span style=\"color: #0000ff;\"><strong>/proc/stat</strong></span>下（以下的截图未截全）：</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201906/801753-20190619214504798-1297192392.png\" alt=\"\"></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">cpu、cpu0后面的这些数字都和前面的us、sy、ni这些对应，具体哪个对应哪个值不重要，感兴趣的可以网上查一下文档。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><span style=\"color: #0000ff;\"><strong>进程cpu</strong></span>的统计值位于<span style=\"color: #0000ff;\"><strong>/proc/{pid}/stat</strong></span>下：</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201906/801753-20190619214423028-82470305.png\" alt=\"\"></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><span style=\"color: #0000ff;\"><strong>线程cpu</strong></span>的统计值位于<span style=\"color: #0000ff;\"><strong>/proc/{pid}/task/{threadId}/stat</strong></span>下：&nbsp;</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201906/801753-20190619215527839-2055018869.png\" alt=\"\">&nbsp;</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">这里面的所有值都是<span style=\"color: #ff0000;\"><strong>从系统启动时间到当前时间的一个值</strong></span>。因此，对于cpu的计算的做法是，采样两个足够短的时间t1、t2：</span></p>\r\n<ul>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">将t1的所有cpu使用情况求和，得到s1</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">将t2的所有cpu使用情况求和，得到s2</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">s2 - s1得到这个时间间隔内的所有时间totalCpuTime</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">第一次的空闲idle1 - 第二次的空闲idle2，获取采样时间内的空闲时间</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">cpu使用率 = 100 * (totalCpuTime - idle) / totalCpuTime</span></li>\r\n</ul>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">其他时间例如us、sy、ni都是类似的计算方式，总结起来说，<span style=\"color: #ff0000;\"><strong>cpu这个值反应的是某个采样时间内的cpu使用情况</strong><span style=\"color: #000000;\">。因此有时候cpu很高，但是打印线程堆栈出来发现高cpu的线程在查询数据库等待中，不要觉得奇怪，因为cpu统计的是采样时间内的数据。</span></span></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">假设top观察某段时间用户空间cpu一直很高，那么意味着这段时间用户的程序一直在占据着cpu做事情。</span></p>\r\n<p>&nbsp;</p>\r\n<p><strong><span style=\"font-size: 18px;\">对load的理解</span></strong></p>\r\n<p><span style=\"font-family: 宋体;\">关于load的含义，其实有些文章把它跟行车过桥联系在一起是比较恰当和好理解的：</span></p>\r\n<div class=\"cnblogs_code\"><div class=\"cnblogs_code_toolbar\"><span class=\"cnblogs_code_copy\"><a href=\"javascript:void(0);\" onclick=\"copyCnblogsCode(this)\" title=\"复制代码\"><img src=\"//common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></a></span></div>\r\n<pre><span style=\"color: #000000;\">一个单核的处理器可以形象得比喻成一条单车道，车辆依次行驶在这条单车道上，前车驶过之后后车才可以行驶。<br>如果前面没有车辆，那么你顺利通过；如果车辆众多，那么你需要等待前车通过之后才可以通过。\r\n\r\n因此，需要些特定的代号表示目前的车流情况，例如：\r\n    ·等于</span><span style=\"color: #800080;\">0.00，</span>表示目前桥面上没有任何的车流。实际上这种情况<span style=\"color: #800080;\">0.00</span>和<span style=\"color: #800080;\">1.00</span><span style=\"color: #000000;\">之间是相同的，总而言之很通畅，过往的车辆可以丝毫不用等待的通过\r\n    ·等于</span><span style=\"color: #800080;\">1.00，</span><span style=\"color: #000000;\">表示刚好是在这座桥的承受范围内。这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢\r\n    ·大于</span><span style=\"color: #800080;\">1.00</span>，那么说明这座桥已经超出负荷，交通严重的拥堵。那么情况有多糟糕? 例如<span style=\"color: #800080;\">2.00</span>的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待<span style=\"color: #800080;\"><br></span></pre>\r\n<div class=\"cnblogs_code_toolbar\"><span class=\"cnblogs_code_copy\"><a href=\"javascript:void(0);\" onclick=\"copyCnblogsCode(this)\" title=\"复制代码\"><img src=\"//common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></a></span></div></div>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">但是比喻终归是比喻，从比喻中我们了解了，load表示的是系统的一个能力，但是我们却不知道什么样的任务会被归到load的计算中。关于具体怎么样的任务会被归到load的计算中，可以使用man uptime命令看一下Linux对于load的解释：</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201906/801753-20190619211749529-532378503.png\" alt=\"\" width=\"625\" height=\"283\"></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">大致意思就是说，系统load是处于运行状态或者不可中断状态的进程的平均数（标红部分表示被算入load的内容）。一个处于运行状态的进程表示<span style=\"color: #ff0000;\"><strong>正在使用cpu或者等待使用cpu</strong></span>，一个不可中断状态的进程表示<span style=\"color: #ff0000;\"><strong>正在等待IO</strong></span>，例如磁盘IO。load的平均值通过3个时间间隔来展示，就是我们看到的1分钟、5分钟、15分钟，load值和cpu核数有关，单核cpu的load=1表示系统一直处在负载状态，但是4核cpu的load=1表示系统有75%的空闲。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">特别注意，<span style=\"color: #ff0000;\"><strong>load指的是所有核的平均值</strong></span>，这和cpu的值是有区别的。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">还有一个重要的点是，查了资料发现，虽然上面一直强调的是\"进程\"，但是<span style=\"color: #0000ff;\"><strong>进程中的线程数也是会被当作不同的进程来计算的</strong></span>，假如一个进程产生1000个线程同时运行，那运行队列的长度就是1000，load average就是1000。</span></p>\r\n<p>&nbsp;</p>\r\n<p><strong><span style=\"font-size: 18px; font-family: \'Microsoft YaHei\';\">请求数和load的关系</span></strong></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">之前我自己一直有个误区：当成千上万的请求过来，且在排队的时候，后面的请求得不到处理，load值必然会升高。认真思考之后，这个观点可真是大错特错，因此特别作为一段写一下和大家分享。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">以Redis为例，我们都知道Redis是单线程模型的，这意味着同一时间可以有无数个请求过来，但是同一时间只有一个命令会被处理（图片来源<a href=\"https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f\">https://www.processon.com/view/5c2ddab0e4b0fa03ce89d14f</a>）：</span></p>\r\n<p><img src=\"https://img2018.cnblogs.com/blog/801753/201909/801753-20190928171602787-1715103501.png\" alt=\"\" width=\"988\" height=\"288\"></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">单独的一条线程接到就绪的命令之后，会将命令转给事件分发器，事件分发器根据命令的类型执行对应的命令处理逻辑。由于只有一条线程，只要后面排队的命令足够多到让这条线程一个接一个不停地处理命令，那么load表现就等于1。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">整个过程中，回看load这个值，它和请求数没有任何关系，真正和load相关的是<span style=\"color: #ff0000;\"><strong>工作线程</strong></span>数量，main线程是工作线程、Timer是工作线程、GC线程也是工作线程，</span><span style=\"font-size: 14px; font-family: 宋体;\">load是以<span style=\"color: #0000ff;\"><strong>线程/进程</strong></span>作为统计指标，无论请求数是多少，最终都需要线程去处理，而工作线程的处理性能直接决定了最终的load值。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">举个例子，假设一个服务中有一个线程池，线程池中线程数量固定为64：</span></p>\r\n<ul>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">正常来说一个任务执行时间为10ms，线程拿到任务10ms处理完，很快回归线程池等待下一个任务到来，自然很少有处于运行状态或者等待IO的线程，从一个统计周期来看load表现为很低</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">某段时间由于系统问题，一个任务10s都处理不完，相当于线程一直在处理任务，在load的统计周期里面就体现出的值=64（不考虑这64条线程外的场景）</span></li>\r\n</ul>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">因此，总而言之，搞清楚load值和请求数、线程数的关系非常重要，想清楚这些才能正确地进行下一步的工作。</span></p>\r\n<p>&nbsp;</p>\r\n<p><span style=\"font-family: \'Microsoft YaHei\';\"><span style=\"font-size: 18px;\"><strong>load高、cpu高的问题排查思路</strong></span></span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">首先抛出一个观点：<span style=\"color: #ff0000;\"><strong>cpu高不是问题，由cpu高引起的load高才是问题，load是判断系统能力指标的依据</strong></span>。</span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">为什么这么说呢，以单核cpu为例，当我们日常cpu在20%、30%的时候其实对cpu资源是浪费的，这意味着绝大多数时候cpu并没有在做事，理论上来说一个系统极限cpu利用率可以达到100%，这意味着cpu完全被利用起来了处理计算密集型任务，例如for循环、md5加密、new对象等等。但是实际不可能出现这种情况，因为应用程序中不消耗cpu的IO不存在是几乎不可能的，例如读取数据库或者读取文件，因此cpu不是越高越好，通常75%是一个需要引起警戒的经验值。</span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">注意前面提到的是\"引起警戒\"，意味着cpu高不一定是问题，但是需要去看一下，尤其是日常的时候，因为通常日常流量不大，cpu是不可能打到这么高的。如果只是普通的代码中确实在处理正常业务那没问题，如果代码里面出现了死循环（例如JDK1.7中经典的HashMap扩容引发的死循环问题），那么几条线程一直占着cpu，最后就会造成load的增高。</span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">在一个Java应用中，排查cpu高的思路通常比较简单，有比较固定的做法：</span></p>\r\n<ul>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">ps -ef | grep java，查询Java应用的进程pid</span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">top -H -p pid，查询占用cpu最高的线程pid</span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">将10进制的线程pid转成16进制的线程pid，例如2000=0x7d0</span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">jstack 进程pid | grep -A 20 \'0x7d0\'，查找nid匹配的线程，查看堆栈，定位引起高cpu的原因</span></li>\r\n</ul>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">网上有很多文章写到这里就停了，实践过程中并不是这样。因为cpu是时间段内的统计值、jstack是一个瞬时堆栈只记录瞬时状态，两个根本不是一个维度的事，因此完全有可能从打印出来的堆栈行号中看到代码停留在以下地方：</span></p>\r\n<ul>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">不消耗cpu的网络IO</span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">for (int i = 0, size = list.size(); i &lt; size; i++) {...}</span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">调用native方法</span></li>\r\n</ul>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">如果完全按照上面那一套步骤做的话碰到这种情况就傻眼了，冥思苦想半天却不得其解，根本不明白为什么这种代码会导致高cpu。针对可能出现的这种情况，实际排查问题的时候<span style=\"color: #ff0000;\"><strong>jstack建议打印5次至少3次</strong></span>，根据多次的堆栈内容，再结合相关<span style=\"color: #ff0000;\"><strong>代码段</strong></span>进行分析，定位高cpu出现的原因，<span style=\"color: #ff0000;\"><strong>高cpu可能是代码段中某个bug导致的而不是堆栈打印出来的那几行导致的</strong></span>。</span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">另外，cpu高的情况还有一种可能的原因，假如一个4核cpu的服务器我们看到总的cpu达到了100%+，按1之后观察每个cpu的us，只有一个达到了90%+，其他都在1%左右（下图只是演示top按1之后的效果并非真实场景）：</span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201909/801753-20190927164622638-1328093925.png\" alt=\"\" width=\"638\" height=\"107\"></span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">这种情况下可以重点考虑是不是频繁FullGC引起的。因为我们知道FullGC的时候会有Stop The World这个动作，多核cpu的服务器，除了GC线程外，在Stop The World的时候都是会挂起的，直到Stop The World结束。以几种老年代垃圾收集器为例：</span></p>\r\n<ul>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\"><span style=\"font-family: 宋体; font-size: 14px;\">Serial Old收集器，全程Stop The World</span></span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\"><span style=\"font-family: 宋体; font-size: 14px;\"><span style=\"font-family: 宋体; font-size: 14px;\">Parallel Old收集器，全程Stop The World</span></span></span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">CMS收集器，它在初始标记与并发标记两个过程中，为了准确标记出需要回收的对象，都会Stop The World，但是相比前两种大大减少了系统停顿时间</span></li>\r\n</ul>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">无论如何，当真正发生Stop The World的时候，就会出现GC线程在占用cpu工作而其他线程挂起的情况，自然表现也就为某个cpu的us很高而且他cpu的us很低。</span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">针对FullGC的问题，排查思路通常为：</span></p>\r\n<ul>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">ps -ef | grep java，查询Java应用的进程pid</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">jstat -gcutil pid 1000 1000，每隔1秒打印一次内存情况共打印1000次，观察老年代（O）、MetaSpace（MU）的内存使用率与FullGC次数</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">确认有频繁的FullGC的发生，查看GC日志，每个应用GC日志配置的路径不同</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">jmap -dump:format=b,file=filename pid，保留现场</span></li>\r\n<li><span style=\"color: #ff0000;\"><strong><span style=\"font-size: 14px; font-family: 宋体;\">重启应用，迅速止血，避免引起更大的线上问题</span></strong></span></li>\r\n<li><span style=\"color: #000000;\"><span style=\"font-size: 14px; font-family: 宋体;\">dump出来的内容，结合MAT分析工具分析内存情况，排查FullGC出现的原因</span></span></li>\r\n</ul>\r\n<p><span style=\"color: #000000;\"><span style=\"font-size: 14px; font-family: 宋体;\">如果FullGC只是发生在老年代区，比较有经验的开发人员还是容易发现问题的，一般都是一些代码bug引起的。MetaSpace发生的FullGC经常会是一些诡异、隐晦的问题，很多和引入的第三方框架使用不当有关或者就是第三方框架有bug导致的，排查起来就很费时间。</span></span></p>\r\n<p><span style=\"color: #000000;\"><span style=\"font-size: 14px; font-family: 宋体;\">那么频繁FullGC之后最终会导致load如何变化呢？这个我没有验证过和看过具体数据，只是通过理论分析，如果所有线程都是空闲的，只有GC线程在一直做FullGC，那么load最后会趋近于1。但是实际不可能，因为如果没有其他线程在运行，怎么可能导致频繁FullGC呢。所以，在其他线程处理任务的情况下Stop The World之后，cpu挂起，任务得不到处理，更大可能的是load会一直升高。</span></span></p>\r\n<p><span style=\"color: #000000;\"><span style=\"font-size: 14px; font-family: 宋体;\">最后顺便提一句，前面一直在讲FullGC，频繁的YoungGC也是会导致load升高的，之前看到过的一个案例是，Object转xml，xml转Object，代码中每处都new XStream()去进行xml序列化与反序列化，回收速度跟不上new的速度，YoungGC次数陡增。</span></span></p>\r\n<p>&nbsp;</p>\r\n<p><span style=\"font-family: \'Microsoft YaHei\';\"><span style=\"font-size: 18px;\"><strong>load高、cpu低的问题排查思路</strong></span></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">关于load的部分，我们可以看到会导致load高的几个因素：</span></p>\r\n<ul>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">线程正在使用cpu</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">线程正在等待使用cpu</span></li>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">线程在执行不可被打断的IO操作</span></li>\r\n</ul>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">既然cpu不高，load高，那么线程要么在进行io要么在等待使用cpu。不过对于后者\"等待使用cpu\"我这里存疑，比如线程池里面10个线程，任务来的很慢，每次只会用到1个线程，那么9个线程都是在等待使用cpu，但是这9个线程明显是不会占据系统资源的，因此我认为自然也不会消耗cpu，所以这个点不考虑。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">因此，在cpu不高的情况下假如load高，大概率io高才是罪魁祸首，它导致的是任务一直在跑，迟迟处理不完，线程无法回归线程池中。首先简单讲讲磁盘io，既然wa表示的是磁盘io等待cpu的百分比，那么我们可以看下wa确认下是不是磁盘io导致的：</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201909/801753-20190928195211804-982283736.png\" alt=\"\"></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">如果是，那么按照cpu高同样的方式打印一下堆栈，查看文件io的部分进行分析，排查原因，例如是不是多线程都在读取本地一个超大的文件到内存。</span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">磁盘io导致的load高，我相信这毕竟是少数，因为Java语言的特点，应用程序更多的高io应当是在处理网络请求，例如：</span></p>\r\n<ul>\r\n<li><span style=\"font-family: 宋体;\">从数据库中获取数据</span></li>\r\n<li><span style=\"font-family: 宋体;\">从Redis中获取数据</span></li>\r\n<li><span style=\"font-family: 宋体;\">调用Http接口从支付宝获取数据</span></li>\r\n<li><span style=\"font-family: 宋体;\">通过dubbo获取某服务中的数据</span></li>\r\n</ul>\r\n<p><span style=\"font-family: 宋体;\">针对这种情况，我觉得首先我们应该对整个系统架构的依赖比较熟悉，例如我画一个草图：</span></p>\r\n<p><span style=\"font-family: 宋体;\"><img src=\"https://img2018.cnblogs.com/blog/801753/201909/801753-20190928200147480-66116604.png\" alt=\"\" width=\"681\" height=\"218\"></span></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">对依赖方的调用任何一个出现比较高的耗时都会增加自身系统的load，出现load高的建议排查方式为：</span></p>\r\n<ul>\r\n<li><span style=\"font-size: 14px; font-family: 宋体;\">查日志，无论是HBase、MySql、Redis调用还是通过http、dubbo调用接口，调用超时，拿连接池中的连接超时，通常都会有错误日志抛出来，只要系统里面没有捕获异常之后不打日志直接吞掉一般都能查到相关的异常</span></li>\r\n<li><span style=\"font-family: 宋体;\">对于dubbo、http的调用，建议做好监控埋点，输出接口名、方法入参（控制大小）、是否成功、调用时长等必要参数，有些时候可能没有超时，但是调用2秒、3秒一样会导致load升高，所以这种时候需要查看方法调用时长进行下一步动作</span></li>\r\n</ul>\r\n<p><span style=\"font-family: 宋体;\"><span style=\"font-family: 宋体;\"><span style=\"font-family: 宋体;\">如果上面的步骤还是没用或者没有对接口调用做埋点，那么还是万能的打印堆栈吧，连续打印五次十次，看一下每次的堆栈是否大多都指向同一个接口的调用，网络io的话，堆栈的最后几行一般都有</span></span></span><span style=\"color: #0000ff;\"><strong><span class=\"string\" style=\"font-size: 14px; font-family: 宋体;\"><span class=\"number\"><span class=\"number\"><span class=\"number\"><span class=\"number\"><span class=\"variable\"><span class=\"variable\"><span class=\"variable\"><span class=\"variable\"><span class=\"variable\"><span class=\"variable\">at java<span class=\"variable\">.net<span class=\"variable\">.SocketInputStream<span class=\"variable\">.read(SocketInputStream<span class=\"variable\">.java:<span class=\"number\">129)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></strong></span><span style=\"font-family: 宋体;\">。</span></p>\r\n<p>&nbsp;</p>\r\n<p><strong><span style=\"font-size: 18px; font-family: \'Microsoft YaHei\';\">Java应用load高的几种原因总结</span></strong></p>\r\n<p><span style=\"font-size: 14px; font-family: 宋体;\">前面说了这么多，这里总结一下load高可能的一些原因：</span></p>\r\n<ul>\r\n<li><span style=\"font-family: 宋体;\">死循环或者不合理的大量循环操作，如果不是循环操作，按照现代cpu的处理速度来说处理一大段代码也就一会会儿的事，基本对能力无消耗</span></li>\r\n<li><span style=\"font-family: 宋体;\">频繁的YoungGC</span></li>\r\n<li><span style=\"font-family: 宋体;\">频繁的FullGC</span></li>\r\n<li><span style=\"font-family: 宋体;\">高磁盘IO</span></li>\r\n<li><span style=\"font-family: 宋体;\">高网络IO</span></li>\r\n</ul>\r\n<p><span style=\"font-family: 宋体;\">系统load高通常都是由于某段发布的代码有bug或者引入某些第三方jar而又使用不合理导致的，因此注意首先区分load高，是由于cpu高导致的还是io高导致的，根据不同的场景采取不同定位问题的方式。</span></p>\r\n<p><span style=\"font-family: 宋体;\">当束手无策时，jstack打印堆栈多分析分析吧，或许能灵光一现能找到错误原因。</span></p>\r\n<p>&nbsp;</p>\r\n<p><span style=\"font-family: \'Microsoft YaHei\';\"><span style=\"font-size: 18px;\"><strong><strong>结语</strong></strong></span></span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">先有理论，把理论想透了，实战碰到问题的时候才能头脑清楚。</span></p>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">坦白讲，cpu和load高排查是一个很偏实战的事情，这方面我还也有很长一条路需要走，身边在这块经验比我丰富的同事多得很。很多人有问过我，项目比较简单，根本没有这种线上问题需要我去排查怎么办？这个问题只能说，平时多积累、多实战是唯一途径，假如没有实战机会，那么推荐三种方式：</span></p>\r\n<ul>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">自己通过代码模拟各种异常，例如FullGC、死锁、死循环，然后利用工具去查，可能比较简单，但是万丈高楼平地起，再复杂的东西都是由简单的变化过来的</span></li>\r\n<li><span style=\"font-family: 宋体; font-size: 14px;\">多上服务器上敲敲top、sar、iostat这些命令，熟记每个命令的作用及输出参数的含义</span></li>\r\n<li><span style=\"font-family: 宋体;\">去网上找一下其他人处理FullGC、cpu高方法的文章，站在巨人的肩膀上，看看前人走过的路，总结记录一些实用的点</span></li>\r\n</ul>\r\n<p><span style=\"font-family: 宋体; font-size: 14px;\">当真的有实战机会来的时候把握住，即使是同事排查的问题，也可以在事后搞清楚问题的来龙去脉，久而久之自然这方面的能力就会提高上去。</span></p>\r\n<p>&nbsp;</p>\r\n</div>', '2019-09-28', 0, 0, 0, 4, 10);
INSERT INTO `app01_article` VALUES (16, ' ', 'asdasdasd', 'asdasdasd', '2019-10-03', 0, 0, 0, 1, 1);
INSERT INTO `app01_article` VALUES (17, '哈哈哈', '基础性<u>机械车间</u><em><u> 酒川</u></em><u>芎</u><strong><u>局</u><span style=\"background-color:#006600;\">数据大</span>V展示大V就京东深V大V</strong>', '基础性<u>机械车间</u><em><u> 酒川</u></em><u>芎</u><strong><u>局</u><span style=\"background-color:#006600;\">数据大</span>V展示大V就京东深V大V</strong>', '2019-10-03', 0, 0, 0, NULL, NULL);
INSERT INTO `app01_article` VALUES (18, '啊实打实大师的', '\r\n	存储历史数据等一系列的程序中。其最初是为了页面抓取(更确切来说,网络抓取)所设计的， 也可以应用在获取API所返回的数据(比如Web Services)或者通用的网络爬虫。\r\n\n\r\n	Scrapy也能帮你实现高阶的爬虫框架，比如爬取时的网站认证、内容的分析处理、重复抓取、分布式爬取等等很复杂的', '<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	存储历史数据等一系列的程序中。其最初是为了页面抓取(更确切来说,网络抓取)所设计的， 也可以应用在获取API所返回的数据(比如Web Services)或者通用的网络爬虫。\r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	Scrapy也能帮你实现高阶的爬虫框架，比如爬取时的网站认证、内容的分析处理、重复抓取、分布式爬取等等很复杂的事。\r\n</p>\n<h2 id=\"安装scrapy\" style=\'font-size:21px;font-family:\"background-color:#FFFFFF;\'>\r\n	安装scrapy\r\n</h2>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	我的测试环境是centos6.5\r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	升级python到最新版的2.7，下面的所有步骤都切换到root用户\r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	由于scrapy目前只能运行在python2上，所以先更新centos上面的python到最新的 <a href=\"https://www.python.org/downloads/release/python-2711/\" target=\"_blank\">Python 2.7.11</a>， 具体方法请google下很多这样的教程。\r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	先安装一些依赖软件\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span> <span class=\"line\">2</span> <span class=\"line\">3</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">yum install python-devel</span> <span class=\"line\">yum install libffi-devel</span> <span class=\"line\">yum install openssl-devel</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	然后安装pyopenssl库\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">pip install pyopenssl</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	安装xlml\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span> <span class=\"line\">2</span> <span class=\"line\">3</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">yum install python-lxml</span> <span class=\"line\">yum install libxml2-devel</span> <span class=\"line\">yum install libxslt-devel</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	安装service-identity\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">pip install service-identity</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	安装twisted\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">pip install scrapy</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	安装scrapy\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">pip install scrapy -U</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	测试scrapy\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">scrapy bench</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	最终成功，太不容易了！\r\n</p>\n<h2 id=\"简单示例\" style=\'font-size:21px;font-family:\"background-color:#FFFFFF;\'>\r\n	简单示例\r\n</h2>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	创建一个python源文件，名为stackoverflow.py，内容如下：\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span> <span class=\"line\">2</span> <span class=\"line\">3</span> <span class=\"line\">4</span> <span class=\"line\">5</span> <span class=\"line\">6</span> <span class=\"line\">7</span> <span class=\"line\">8</span> <span class=\"line\">9</span> <span class=\"line\">10</span> <span class=\"line\">11</span> <span class=\"line\">12</span> <span class=\"line\">13</span> <span class=\"line\">14</span> <span class=\"line\">15</span> <span class=\"line\">16</span> <span class=\"line\">17</span> <span class=\"line\">18</span> <span class=\"line\">19</span> <span class=\"line\">20</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span> <span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title\">StackOverflowSpider</span><span class=\"params\">(scrapy.Spider)</span>:</span> <span class=\"line\"> name = <span class=\"string\">\'stackoverflow\'</span></span> <span class=\"line\"> start_urls = [<span class=\"string\">\'http://stackoverflow.com/questions?sort=votes\'</span>]</span> <span class=\"line\"> <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span><span class=\"params\">(self, response)</span>:</span></span> <span class=\"line\"> <span class=\"keyword\">for</span> href <span class=\"keyword\">in</span> response.css(<span class=\"string\">\'.question-summary h3 a::attr(href)\'</span>):</span> <span class=\"line\"> full_url = response.urljoin(href.extract())</span> <span class=\"line\"> <span class=\"keyword\">yield</span> scrapy.Request(full_url, callback=self.parse_question)</span> <span class=\"line\"> <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_question</span><span class=\"params\">(self, response)</span>:</span></span> <span class=\"line\"> <span class=\"keyword\">yield</span> {</span> <span class=\"line\"> <span class=\"string\">\'title\'</span>: response.css(<span class=\"string\">\'h1 a::text\'</span>).extract()[<span class=\"number\">0</span>],</span> <span class=\"line\"> <span class=\"string\">\'votes\'</span>: response.css(<span class=\"string\">\'.question .vote-count-post::text\'</span>).extract()[<span class=\"number\">0</span>],</span> <span class=\"line\"> <span class=\"string\">\'body\'</span>: response.css(<span class=\"string\">\'.question .post-text\'</span>).extract()[<span class=\"number\">0</span>],</span> <span class=\"line\"> <span class=\"string\">\'tags\'</span>: response.css(<span class=\"string\">\'.question .post-tag::text\'</span>).extract(),</span> <span class=\"line\"> <span class=\"string\">\'link\'</span>: response.url,</span> <span class=\"line\"> }</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	运行：\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">scrapy runspider stackoverflow_spider.py -o top-stackoverflow-questions.json</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	结果类似下面：\r\n</p>\n<table style=\'margin:0px;padding:0px;border:1px solid #C0C0C0;color:#000000;font-family:\"font-size:14px;background-color:#FFFFFF;\'>\n<tbody>\n<tr>\n<td class=\"gutter\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">1</span> <span class=\"line\">2</span> <span class=\"line\">3</span> <span class=\"line\">4</span> <span class=\"line\">5</span> <span class=\"line\">6</span> <span class=\"line\">7</span> <span class=\"line\">8</span> <span class=\"line\">9</span> <span class=\"line\">10</span> <span class=\"line\">11</span> <span class=\"line\">12</span> <span class=\"line\">13</span> <span class=\"line\">14</span> <span class=\"line\">15</span></pre>\n</td>\n<td class=\"code\" style=\"border:1px solid #C0C0C0;\">\n<pre><span class=\"line\">[{</span> <span class=\"line\"> \"body\": \"... LONG HTML HERE ...\",</span> <span class=\"line\"> \"link\": \"http://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array\",</span> <span class=\"line\"> \"tags\": [\"java\", \"c++\", \"performance\", \"optimization\"],</span> <span class=\"line\"> \"title\": \"Why is processing a sorted array faster than an unsorted array?\",</span> <span class=\"line\"> \"votes\": \"9924\"</span> <span class=\"line\">},</span> <span class=\"line\">{</span> <span class=\"line\"> \"body\": \"... LONG HTML HERE ...\",</span> <span class=\"line\"> \"link\": \"http://stackoverflow.com/questions/1260748/how-do-i-remove-a-git-submodule\",</span> <span class=\"line\"> \"tags\": [\"git\", \"git-submodules\"],</span> <span class=\"line\"> \"title\": \"How do I remove a Git submodule?\",</span> <span class=\"line\"> \"votes\": \"1764\"</span> <span class=\"line\">},</span> <span class=\"line\">...]</span></pre>\n</td>\n</tr>\n</tbody>\n</table>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	 \r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	当你运行scrapy runspider somefile.py这条语句的时候，Scrapy会去寻找源文件中定义的一个spider并且交给爬虫引擎来执行它。 start_urls属性定义了开始的URL，爬虫会通过它来构建初始的请求，返回response后再调用默认的回调方法parse并传入这个response。 我们在parse回调方法中通过使用css选择器提取每个提问页面链接的href属性值，然后yield另外一个请求， 并注册parse_question回调方法，在这个请求完成后被执行。\r\n</p>\n<p style=\'font-family:\"font-size:14px;background-color:#FFFFFF;\'>\r\n	处理流程图：\r\n</p>', '2019-10-04', 0, 0, 0, NULL, NULL);

-- ----------------------------
-- Table structure for app01_article2tag
-- ----------------------------
DROP TABLE IF EXISTS `app01_article2tag`;
CREATE TABLE `app01_article2tag`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `article_id` int(11) NOT NULL,
  `tag_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app01_article2tag_article_id_35c1561c_fk_app01_article_id`(`article_id`) USING BTREE,
  INDEX `app01_article2tag_tag_id_d24dfcf8_fk_app01_tag_id`(`tag_id`) USING BTREE,
  CONSTRAINT `app01_article2tag_article_id_35c1561c_fk_app01_article_id` FOREIGN KEY (`article_id`) REFERENCES `app01_article` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `app01_article2tag_tag_id_d24dfcf8_fk_app01_tag_id` FOREIGN KEY (`tag_id`) REFERENCES `app01_tag` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 15 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_article2tag
-- ----------------------------
INSERT INTO `app01_article2tag` VALUES (1, 1, 1);
INSERT INTO `app01_article2tag` VALUES (3, 3, 3);
INSERT INTO `app01_article2tag` VALUES (4, 4, 3);
INSERT INTO `app01_article2tag` VALUES (5, 4, 3);
INSERT INTO `app01_article2tag` VALUES (6, 5, 10);
INSERT INTO `app01_article2tag` VALUES (7, 6, 4);
INSERT INTO `app01_article2tag` VALUES (8, 7, 4);
INSERT INTO `app01_article2tag` VALUES (9, 9, 5);
INSERT INTO `app01_article2tag` VALUES (10, 10, 5);
INSERT INTO `app01_article2tag` VALUES (11, 11, 6);
INSERT INTO `app01_article2tag` VALUES (12, 12, 8);
INSERT INTO `app01_article2tag` VALUES (13, 13, 9);
INSERT INTO `app01_article2tag` VALUES (14, 16, 1);

-- ----------------------------
-- Table structure for app01_category
-- ----------------------------
DROP TABLE IF EXISTS `app01_category`;
CREATE TABLE `app01_category`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `site_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app01_category_site_id_6217ae50_fk_app01_site_id`(`site_id`) USING BTREE,
  CONSTRAINT `app01_category_site_id_6217ae50_fk_app01_site_id` FOREIGN KEY (`site_id`) REFERENCES `app01_site` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 11 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_category
-- ----------------------------
INSERT INTO `app01_category` VALUES (1, 'SR的分类一', 1);
INSERT INTO `app01_category` VALUES (2, 'SR的分类二', 1);
INSERT INTO `app01_category` VALUES (3, 'SR的分类三', 1);
INSERT INTO `app01_category` VALUES (4, 'egon分类一', 3);
INSERT INTO `app01_category` VALUES (5, 'egon分类二', 3);
INSERT INTO `app01_category` VALUES (6, 'tank分类一', 2);
INSERT INTO `app01_category` VALUES (7, 'tank分类二', 2);
INSERT INTO `app01_category` VALUES (8, 'tank分类三', 2);
INSERT INTO `app01_category` VALUES (9, 'user的分类一', 4);
INSERT INTO `app01_category` VALUES (10, 'user的分类二', 4);

-- ----------------------------
-- Table structure for app01_comment
-- ----------------------------
DROP TABLE IF EXISTS `app01_comment`;
CREATE TABLE `app01_comment`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `content` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `create_time` date NOT NULL,
  `article_id` int(11) NOT NULL,
  `parent_id` int(11) NULL DEFAULT NULL,
  `user_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app01_comment_article_id_2bf4f73b_fk_app01_article_id`(`article_id`) USING BTREE,
  INDEX `app01_comment_parent_id_a8e69cb8_fk_app01_comment_id`(`parent_id`) USING BTREE,
  INDEX `app01_comment_user_id_7f913f03_fk_app01_userinfo_id`(`user_id`) USING BTREE,
  CONSTRAINT `app01_comment_article_id_2bf4f73b_fk_app01_article_id` FOREIGN KEY (`article_id`) REFERENCES `app01_article` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `app01_comment_parent_id_a8e69cb8_fk_app01_comment_id` FOREIGN KEY (`parent_id`) REFERENCES `app01_comment` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `app01_comment_user_id_7f913f03_fk_app01_userinfo_id` FOREIGN KEY (`user_id`) REFERENCES `app01_userinfo` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 24 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_comment
-- ----------------------------
INSERT INTO `app01_comment` VALUES (1, 'asdasdasdasd', '2019-10-03', 9, NULL, 31);
INSERT INTO `app01_comment` VALUES (2, 'asdasdasd', '2019-10-03', 7, NULL, 31);
INSERT INTO `app01_comment` VALUES (3, 'asdasdasdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (4, 'asdasdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (5, 'asdasdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (6, 'asdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (7, '@SR\nasdasdasdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (8, '@SR\nasdasdasdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (9, 'asdasdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (10, '@SR\n子评论', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (11, 'asdasda', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (12, '@SR\n子评论', '2019-10-03', 13, 4, 31);
INSERT INTO `app01_comment` VALUES (13, '', '2019-10-03', 13, 11, 31);
INSERT INTO `app01_comment` VALUES (14, '', '2019-10-03', 13, 11, 31);
INSERT INTO `app01_comment` VALUES (15, 'asdasdasd', '2019-10-03', 13, 14, 31);
INSERT INTO `app01_comment` VALUES (16, 'asdasdasd', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (17, '跟评论', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (18, '子评论', '2019-10-03', 13, 17, 31);
INSERT INTO `app01_comment` VALUES (19, '啊实打实大师的', '2019-10-03', 13, 15, 31);
INSERT INTO `app01_comment` VALUES (20, '爱上大大大大 ', '2019-10-03', 13, NULL, 31);
INSERT INTO `app01_comment` VALUES (21, 'asdasd', '2019-10-03', 1, NULL, 31);
INSERT INTO `app01_comment` VALUES (22, 'asdasdasd', '2019-10-03', 1, 21, 31);
INSERT INTO `app01_comment` VALUES (23, '078', '2019-10-03', 1, NULL, 38);

-- ----------------------------
-- Table structure for app01_site
-- ----------------------------
DROP TABLE IF EXISTS `app01_site`;
CREATE TABLE `app01_site`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `site_title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `site_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `site_theme` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_site
-- ----------------------------
INSERT INTO `app01_site` VALUES (1, '年少有为', 'SR', 'SR.css');
INSERT INTO `app01_site` VALUES (2, 'tank的个人站点', 'tank', 'tank.css');
INSERT INTO `app01_site` VALUES (3, 'egon个人站点', 'egon', 'egon.css');
INSERT INTO `app01_site` VALUES (4, 'user个人站点', 'user', 'user.css');

-- ----------------------------
-- Table structure for app01_tag
-- ----------------------------
DROP TABLE IF EXISTS `app01_tag`;
CREATE TABLE `app01_tag`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `site_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app01_tag_site_id_7f071b10_fk_app01_site_id`(`site_id`) USING BTREE,
  CONSTRAINT `app01_tag_site_id_7f071b10_fk_app01_site_id` FOREIGN KEY (`site_id`) REFERENCES `app01_site` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 13 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_tag
-- ----------------------------
INSERT INTO `app01_tag` VALUES (1, 'SR的标签一', 1);
INSERT INTO `app01_tag` VALUES (3, 'SR的标签三', 1);
INSERT INTO `app01_tag` VALUES (4, 'tank标签一', 2);
INSERT INTO `app01_tag` VALUES (5, 'tank的标签二', 2);
INSERT INTO `app01_tag` VALUES (6, 'tank的标签三', 2);
INSERT INTO `app01_tag` VALUES (7, 'egon标签一', 3);
INSERT INTO `app01_tag` VALUES (8, 'egon标签二', 3);
INSERT INTO `app01_tag` VALUES (9, 'egon标签三', 3);
INSERT INTO `app01_tag` VALUES (10, 'SR的标签二', 1);
INSERT INTO `app01_tag` VALUES (11, 'user的标签一', 4);
INSERT INTO `app01_tag` VALUES (12, 'user的标签二', 4);

-- ----------------------------
-- Table structure for app01_upanddown
-- ----------------------------
DROP TABLE IF EXISTS `app01_upanddown`;
CREATE TABLE `app01_upanddown`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `is_up` tinyint(1) NOT NULL,
  `article_id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app01_upanddown_article_id_5a7b1add_fk_app01_article_id`(`article_id`) USING BTREE,
  INDEX `app01_upanddown_user_id_cdb8debc_fk_app01_userinfo_id`(`user_id`) USING BTREE,
  CONSTRAINT `app01_upanddown_article_id_5a7b1add_fk_app01_article_id` FOREIGN KEY (`article_id`) REFERENCES `app01_article` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `app01_upanddown_user_id_cdb8debc_fk_app01_userinfo_id` FOREIGN KEY (`user_id`) REFERENCES `app01_userinfo` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_upanddown
-- ----------------------------
INSERT INTO `app01_upanddown` VALUES (1, 1, 9, 31);

-- ----------------------------
-- Table structure for app01_userinfo
-- ----------------------------
DROP TABLE IF EXISTS `app01_userinfo`;
CREATE TABLE `app01_userinfo`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `password` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `last_login` datetime(6) NULL DEFAULT NULL,
  `is_superuser` tinyint(1) NOT NULL,
  `username` varchar(150) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `first_name` varchar(30) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `last_name` varchar(30) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `email` varchar(254) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `is_staff` tinyint(1) NOT NULL,
  `is_active` tinyint(1) NOT NULL,
  `date_joined` datetime(6) NOT NULL,
  `phone` bigint(20) NULL DEFAULT NULL,
  `avatar` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `register_time` date NOT NULL,
  `site_id` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `username`(`username`) USING BTREE,
  UNIQUE INDEX `site_id`(`site_id`) USING BTREE,
  CONSTRAINT `app01_userinfo_site_id_9e441d03_fk_app01_site_id` FOREIGN KEY (`site_id`) REFERENCES `app01_site` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 40 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of app01_userinfo
-- ----------------------------
INSERT INTO `app01_userinfo` VALUES (25, 'pbkdf2_sha256$36000$ft8RMdq3rkt2$L2671NolK8hm5UBE1pObsZPgzUYKWE40DM2t08AzviA=', '2019-09-27 14:08:16.855900', 0, 'admin', '', '', '11401339@qq.com', 0, 1, '2019-09-27 12:07:07.809900', NULL, 'avatar/333.jpg', '2019-09-27', NULL);
INSERT INTO `app01_userinfo` VALUES (31, 'pbkdf2_sha256$36000$mX8h4AbU9HvT$UFCMU5ZsSOX4bC1RDeEZEj78NpvbBtkXwRVD20Lm4po=', '2019-10-07 08:46:17.672000', 1, 'SR', '', '', '11401339@qq.com', 1, 1, '2019-09-27 14:41:45.000000', NULL, 'avatar/default.png', '2019-09-27', 1);
INSERT INTO `app01_userinfo` VALUES (32, 'pbkdf2_sha256$36000$auX190rtiEH7$fus28A5PTecjunAiV9E4M2cBfqlpR0HshBkXQ7jtxeU=', NULL, 0, 'egon', '', '', '11401339@qq.com', 0, 1, '2019-09-27 15:10:54.000000', NULL, 'avatar/333.jpg', '2019-09-27', 3);
INSERT INTO `app01_userinfo` VALUES (33, 'pbkdf2_sha256$36000$UW1KPpySiErs$7QAXZmDPLU41hqj+z79bh7GhdgA9kM3fBkZx9BJ7Tk0=', NULL, 0, 'tank', '', '', '11401339@qq.com', 0, 1, '2019-09-27 15:11:03.000000', NULL, 'avatar/555.jpg', '2019-09-27', 2);
INSERT INTO `app01_userinfo` VALUES (34, 'pbkdf2_sha256$36000$Ly8H5FyoOpKc$5Bid0Eef12GrM61PxD9p07BPcQJ/UvnPwZO/VIsoNNo=', '2019-09-28 07:00:53.000000', 0, 'user', '', '', '123@qq.com', 0, 1, '2019-09-28 06:58:57.000000', NULL, 'avatar/222.jpg', '2019-09-28', 4);
INSERT INTO `app01_userinfo` VALUES (38, 'pbkdf2_sha256$36000$XuhBvEkCZlLD$ut2DjWxZEPm4HFA6QxAgo2mRQW/2DpRXeiYUP1Wc4js=', '2019-10-03 11:28:14.085000', 0, 'yangzai', '', '', '1394640131@qq.com', 0, 1, '2019-10-03 11:27:26.470000', NULL, 'avatar/表关系_bqRv2BD.png', '2019-10-03', NULL);
INSERT INTO `app01_userinfo` VALUES (39, 'pbkdf2_sha256$36000$BeiqP96n7l8w$xnjbvGH380Uc9VuU1YX0Ep1b9WXP6WouFm1fYD2zQTI=', '2019-10-05 08:21:45.801200', 1, 'qwe', '', '', '', 1, 1, '2019-10-05 08:21:31.895200', NULL, 'avatar/default.png', '2019-10-05', NULL);

-- ----------------------------
-- Table structure for app01_userinfo_groups
-- ----------------------------
DROP TABLE IF EXISTS `app01_userinfo_groups`;
CREATE TABLE `app01_userinfo_groups`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `userinfo_id` int(11) NOT NULL,
  `group_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `app01_userinfo_groups_userinfo_id_group_id_48ba2aa6_uniq`(`userinfo_id`, `group_id`) USING BTREE,
  INDEX `app01_userinfo_groups_group_id_30b9b2c4_fk_auth_group_id`(`group_id`) USING BTREE,
  CONSTRAINT `app01_userinfo_groups_group_id_30b9b2c4_fk_auth_group_id` FOREIGN KEY (`group_id`) REFERENCES `auth_group` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `app01_userinfo_groups_userinfo_id_04be482a_fk_app01_userinfo_id` FOREIGN KEY (`userinfo_id`) REFERENCES `app01_userinfo` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Table structure for app01_userinfo_user_permissions
-- ----------------------------
DROP TABLE IF EXISTS `app01_userinfo_user_permissions`;
CREATE TABLE `app01_userinfo_user_permissions`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `userinfo_id` int(11) NOT NULL,
  `permission_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `app01_userinfo_user_perm_userinfo_id_permission_i_8bd06903_uniq`(`userinfo_id`, `permission_id`) USING BTREE,
  INDEX `app01_userinfo_user__permission_id_826033c9_fk_auth_perm`(`permission_id`) USING BTREE,
  CONSTRAINT `app01_userinfo_user__permission_id_826033c9_fk_auth_perm` FOREIGN KEY (`permission_id`) REFERENCES `auth_permission` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `app01_userinfo_user__userinfo_id_3a67a872_fk_app01_use` FOREIGN KEY (`userinfo_id`) REFERENCES `app01_userinfo` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Table structure for auth_group
-- ----------------------------
DROP TABLE IF EXISTS `auth_group`;
CREATE TABLE `auth_group`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(80) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `name`(`name`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Table structure for auth_group_permissions
-- ----------------------------
DROP TABLE IF EXISTS `auth_group_permissions`;
CREATE TABLE `auth_group_permissions`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `group_id` int(11) NOT NULL,
  `permission_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `auth_group_permissions_group_id_permission_id_0cd325b0_uniq`(`group_id`, `permission_id`) USING BTREE,
  INDEX `auth_group_permissio_permission_id_84c5c92e_fk_auth_perm`(`permission_id`) USING BTREE,
  CONSTRAINT `auth_group_permissio_permission_id_84c5c92e_fk_auth_perm` FOREIGN KEY (`permission_id`) REFERENCES `auth_permission` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `auth_group_permissions_group_id_b120cbf9_fk_auth_group_id` FOREIGN KEY (`group_id`) REFERENCES `auth_group` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Table structure for auth_permission
-- ----------------------------
DROP TABLE IF EXISTS `auth_permission`;
CREATE TABLE `auth_permission`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `content_type_id` int(11) NOT NULL,
  `codename` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `auth_permission_content_type_id_codename_01ab375a_uniq`(`content_type_id`, `codename`) USING BTREE,
  CONSTRAINT `auth_permission_content_type_id_2f476e4b_fk_django_co` FOREIGN KEY (`content_type_id`) REFERENCES `django_content_type` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 40 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of auth_permission
-- ----------------------------
INSERT INTO `auth_permission` VALUES (1, 'Can add log entry', 1, 'add_logentry');
INSERT INTO `auth_permission` VALUES (2, 'Can change log entry', 1, 'change_logentry');
INSERT INTO `auth_permission` VALUES (3, 'Can delete log entry', 1, 'delete_logentry');
INSERT INTO `auth_permission` VALUES (4, 'Can add permission', 2, 'add_permission');
INSERT INTO `auth_permission` VALUES (5, 'Can change permission', 2, 'change_permission');
INSERT INTO `auth_permission` VALUES (6, 'Can delete permission', 2, 'delete_permission');
INSERT INTO `auth_permission` VALUES (7, 'Can add group', 3, 'add_group');
INSERT INTO `auth_permission` VALUES (8, 'Can change group', 3, 'change_group');
INSERT INTO `auth_permission` VALUES (9, 'Can delete group', 3, 'delete_group');
INSERT INTO `auth_permission` VALUES (10, 'Can add content type', 4, 'add_contenttype');
INSERT INTO `auth_permission` VALUES (11, 'Can change content type', 4, 'change_contenttype');
INSERT INTO `auth_permission` VALUES (12, 'Can delete content type', 4, 'delete_contenttype');
INSERT INTO `auth_permission` VALUES (13, 'Can add session', 5, 'add_session');
INSERT INTO `auth_permission` VALUES (14, 'Can change session', 5, 'change_session');
INSERT INTO `auth_permission` VALUES (15, 'Can delete session', 5, 'delete_session');
INSERT INTO `auth_permission` VALUES (16, 'Can add user', 6, 'add_userinfo');
INSERT INTO `auth_permission` VALUES (17, 'Can change user', 6, 'change_userinfo');
INSERT INTO `auth_permission` VALUES (18, 'Can delete user', 6, 'delete_userinfo');
INSERT INTO `auth_permission` VALUES (19, 'Can add article', 7, 'add_article');
INSERT INTO `auth_permission` VALUES (20, 'Can change article', 7, 'change_article');
INSERT INTO `auth_permission` VALUES (21, 'Can delete article', 7, 'delete_article');
INSERT INTO `auth_permission` VALUES (22, 'Can add article2 tag', 8, 'add_article2tag');
INSERT INTO `auth_permission` VALUES (23, 'Can change article2 tag', 8, 'change_article2tag');
INSERT INTO `auth_permission` VALUES (24, 'Can delete article2 tag', 8, 'delete_article2tag');
INSERT INTO `auth_permission` VALUES (25, 'Can add category', 9, 'add_category');
INSERT INTO `auth_permission` VALUES (26, 'Can change category', 9, 'change_category');
INSERT INTO `auth_permission` VALUES (27, 'Can delete category', 9, 'delete_category');
INSERT INTO `auth_permission` VALUES (28, 'Can add comment', 10, 'add_comment');
INSERT INTO `auth_permission` VALUES (29, 'Can change comment', 10, 'change_comment');
INSERT INTO `auth_permission` VALUES (30, 'Can delete comment', 10, 'delete_comment');
INSERT INTO `auth_permission` VALUES (31, 'Can add site', 11, 'add_site');
INSERT INTO `auth_permission` VALUES (32, 'Can change site', 11, 'change_site');
INSERT INTO `auth_permission` VALUES (33, 'Can delete site', 11, 'delete_site');
INSERT INTO `auth_permission` VALUES (34, 'Can add tag', 12, 'add_tag');
INSERT INTO `auth_permission` VALUES (35, 'Can change tag', 12, 'change_tag');
INSERT INTO `auth_permission` VALUES (36, 'Can delete tag', 12, 'delete_tag');
INSERT INTO `auth_permission` VALUES (37, 'Can add up and down', 13, 'add_upanddown');
INSERT INTO `auth_permission` VALUES (38, 'Can change up and down', 13, 'change_upanddown');
INSERT INTO `auth_permission` VALUES (39, 'Can delete up and down', 13, 'delete_upanddown');

-- ----------------------------
-- Table structure for django_admin_log
-- ----------------------------
DROP TABLE IF EXISTS `django_admin_log`;
CREATE TABLE `django_admin_log`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `action_time` datetime(6) NOT NULL,
  `object_id` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `object_repr` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `action_flag` smallint(5) UNSIGNED NOT NULL,
  `change_message` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `content_type_id` int(11) NULL DEFAULT NULL,
  `user_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `django_admin_log_content_type_id_c4bce8eb_fk_django_co`(`content_type_id`) USING BTREE,
  INDEX `django_admin_log_user_id_c564eba6_fk_app01_userinfo_id`(`user_id`) USING BTREE,
  CONSTRAINT `django_admin_log_content_type_id_c4bce8eb_fk_django_co` FOREIGN KEY (`content_type_id`) REFERENCES `django_content_type` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT,
  CONSTRAINT `django_admin_log_user_id_c564eba6_fk_app01_userinfo_id` FOREIGN KEY (`user_id`) REFERENCES `app01_userinfo` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT
) ENGINE = InnoDB AUTO_INCREMENT = 90 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of django_admin_log
-- ----------------------------
INSERT INTO `django_admin_log` VALUES (1, '2019-09-27 14:59:56.031900', '1', 'SR', 1, '[{\"added\": {}}]', 11, 31);
INSERT INTO `django_admin_log` VALUES (2, '2019-09-27 15:00:16.349900', '1', 'SR的分类一', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (3, '2019-09-27 15:00:22.679900', '1', '在vscode中配置python环境', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (4, '2019-09-27 15:01:01.945900', '2', '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (5, '2019-09-27 15:01:52.578900', '2', 'tank', 1, '[{\"added\": {}}]', 11, 31);
INSERT INTO `django_admin_log` VALUES (6, '2019-09-27 15:02:14.717900', '3', 'egon', 1, '[{\"added\": {}}]', 11, 31);
INSERT INTO `django_admin_log` VALUES (7, '2019-09-27 15:02:26.186900', '3', '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (8, '2019-09-27 15:03:09.147900', '2', 'SR的分类二', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (9, '2019-09-27 15:03:17.377900', '3', 'SR的分类三', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (10, '2019-09-27 15:03:32.329900', '4', 'egon分类一', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (11, '2019-09-27 15:03:44.102900', '5', 'egon分类二', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (12, '2019-09-27 15:03:52.966900', '6', 'tank分类一', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (13, '2019-09-27 15:04:04.428900', '7', 'tank分类二', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (14, '2019-09-27 15:04:21.324900', '8', 'tank分类三', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (15, '2019-09-27 15:04:28.089900', '4', '品Spring：SpringBoot和Spring到底有没有本质的不同？', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (16, '2019-09-27 15:04:48.037900', '5', 'golang1.13中重要的新特新', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (17, '2019-09-27 15:05:28.152900', '6', '注解在Java中是如何工作的', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (18, '2019-09-27 15:05:50.879900', '7', 'Spring Boot 配置元数据指南', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (19, '2019-09-27 15:06:12.195900', '8', 'oracle异机恢复测试', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (20, '2019-09-27 15:06:47.603900', '9', 'MyBatis 插件使用-自定义简单的分页插件', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (21, '2019-09-27 15:07:09.401900', '10', '代码不规范，同事皮锤现（上）', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (22, '2019-09-27 15:08:09.223900', '11', '数据结构之二叉树篇卷三 -- 二叉树非递归遍历（With Java)', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (23, '2019-09-27 15:08:28.296900', '12', '什么样的代码是好代码？', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (24, '2019-09-27 15:08:46.668900', '13', 'linux系统下开发环境安装与配置', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (25, '2019-09-27 15:12:04.818900', '31', 'SR', 2, '[{\"changed\": {\"fields\": [\"site\"]}}]', 6, 31);
INSERT INTO `django_admin_log` VALUES (26, '2019-09-27 15:12:13.533900', '32', 'egon', 2, '[{\"changed\": {\"fields\": [\"site\"]}}]', 6, 31);
INSERT INTO `django_admin_log` VALUES (27, '2019-09-27 15:12:21.620900', '33', 'tank', 2, '[{\"changed\": {\"fields\": [\"site\"]}}]', 6, 31);
INSERT INTO `django_admin_log` VALUES (28, '2019-09-27 15:13:58.238900', '1', 'SR的标签一', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (29, '2019-09-27 15:14:06.689900', '2', 'SR的标签一', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (30, '2019-09-27 15:14:12.530900', '3', 'SR的标签三', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (31, '2019-09-27 15:14:22.711900', '4', 'tank标签一', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (32, '2019-09-27 15:14:33.465900', '5', 'tank的标签二', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (33, '2019-09-27 15:14:41.941900', '6', 'tank的标签三', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (34, '2019-09-27 15:14:51.779900', '7', 'egon标签一', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (35, '2019-09-27 15:14:59.881900', '8', 'egon标签二', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (36, '2019-09-27 15:15:10.382900', '9', 'egon标签三', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (37, '2019-09-27 15:15:35.438900', '1', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (38, '2019-09-27 15:15:40.408900', '2', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (39, '2019-09-27 15:15:47.943900', '3', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (40, '2019-09-27 15:15:53.450900', '4', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (41, '2019-09-27 15:16:16.767900', '2', 'SR的标签一', 3, '', 12, 31);
INSERT INTO `django_admin_log` VALUES (42, '2019-09-27 15:16:26.864900', '10', 'SR的标签二', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (43, '2019-09-27 15:16:58.914900', '5', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (44, '2019-09-27 15:17:09.971900', '6', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (45, '2019-09-27 15:17:21.639900', '7', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (46, '2019-09-27 15:17:27.287900', '8', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (47, '2019-09-27 15:17:32.474900', '9', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (48, '2019-09-27 15:17:38.069900', '10', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (49, '2019-09-27 15:17:45.985900', '11', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (50, '2019-09-27 15:17:53.904900', '12', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (51, '2019-09-27 15:18:01.105900', '13', 'Article2Tag object', 1, '[{\"added\": {}}]', 8, 31);
INSERT INTO `django_admin_log` VALUES (52, '2019-09-28 07:21:32.872200', '4', 'user', 1, '[{\"added\": {}}]', 11, 31);
INSERT INTO `django_admin_log` VALUES (53, '2019-09-28 07:21:52.633200', '9', 'user的分类一', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (54, '2019-09-28 07:21:59.144200', '14', 'python基础', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (55, '2019-09-28 07:22:46.063200', '10', 'user的分类二', 1, '[{\"added\": {}}]', 9, 31);
INSERT INTO `django_admin_log` VALUES (56, '2019-09-28 07:22:47.750200', '15', 'Django框架', 1, '[{\"added\": {}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (57, '2019-09-28 07:23:31.695200', '11', 'user的标签一', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (58, '2019-09-28 07:23:46.310200', '12', 'user的标签二', 1, '[{\"added\": {}}]', 12, 31);
INSERT INTO `django_admin_log` VALUES (59, '2019-09-28 07:23:59.958200', '34', 'user', 2, '[{\"changed\": {\"fields\": [\"site\"]}}]', 6, 31);
INSERT INTO `django_admin_log` VALUES (60, '2019-09-28 13:59:30.592200', '15', 'Django框架', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (61, '2019-09-28 14:00:28.091200', '14', 'python基础', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (62, '2019-09-28 14:01:59.600200', '13', 'linux系统下开发环境安装与配置', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (63, '2019-09-28 14:02:08.109200', '12', '什么样的代码是好代码？', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (64, '2019-09-28 14:02:13.793200', '11', '数据结构之二叉树篇卷三 -- 二叉树非递归遍历（With Java)', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (65, '2019-09-28 14:02:26.473200', '9', 'MyBatis 插件使用-自定义简单的分页插件', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (66, '2019-09-28 14:02:35.990200', '10', '代码不规范，同事皮锤现（上）', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (67, '2019-09-28 14:02:45.449200', '8', 'oracle异机恢复测试', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (68, '2019-09-28 14:02:51.666200', '7', 'Spring Boot 配置元数据指南', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (69, '2019-09-28 14:03:01.608200', '6', '注解在Java中是如何工作的', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (70, '2019-09-28 14:03:11.282200', '5', 'golang1.13中重要的新特新', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (71, '2019-09-28 14:03:17.024200', '4', '品Spring：SpringBoot和Spring到底有没有本质的不同？', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (72, '2019-09-28 14:03:25.515200', '3', '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (73, '2019-09-28 14:03:30.198200', '2', '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (74, '2019-09-28 14:03:34.857200', '1', '在vscode中配置python环境', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (75, '2019-10-03 03:38:56.042000', '3', '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (76, '2019-10-03 03:39:03.695000', '2', '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', 3, '', 7, 31);
INSERT INTO `django_admin_log` VALUES (77, '2019-10-03 03:39:18.416000', '14', 'python基础', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (78, '2019-10-03 03:39:35.932000', '12', '什么样的代码是好代码？', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (79, '2019-10-03 03:39:45.537000', '13', 'linux系统下开发环境安装与配置', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (80, '2019-10-03 03:39:56.706000', '11', '数据结构之二叉树篇卷三 -- 二叉树非递归遍历（With Java)', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (81, '2019-10-03 03:40:04.315000', '10', '代码不规范，同事皮锤现（上）', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (82, '2019-10-03 03:40:12.100000', '9', 'MyBatis 插件使用-自定义简单的分页插件', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (83, '2019-10-03 03:40:22.459000', '8', 'oracle异机恢复测试', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (84, '2019-10-03 03:40:31.426000', '7', 'Spring Boot 配置元数据指南', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (85, '2019-10-03 03:40:42.132000', '6', '注解在Java中是如何工作的', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (86, '2019-10-03 03:40:52.592000', '5', 'golang1.13中重要的新特新', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (87, '2019-10-03 03:41:01.093000', '4', '品Spring：SpringBoot和Spring到底有没有本质的不同？', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (88, '2019-10-03 03:41:11.799000', '3', '夯实Java基础系列6：一文搞懂抽象类和接口，从基础到面试题，揭秘其本质区别！', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);
INSERT INTO `django_admin_log` VALUES (89, '2019-10-03 03:41:24.885000', '1', '在vscode中配置python环境', 2, '[{\"changed\": {\"fields\": [\"content\"]}}]', 7, 31);

-- ----------------------------
-- Table structure for django_content_type
-- ----------------------------
DROP TABLE IF EXISTS `django_content_type`;
CREATE TABLE `django_content_type`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `app_label` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `model` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `django_content_type_app_label_model_76bd3d3b_uniq`(`app_label`, `model`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 14 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of django_content_type
-- ----------------------------
INSERT INTO `django_content_type` VALUES (1, 'admin', 'logentry');
INSERT INTO `django_content_type` VALUES (7, 'app01', 'article');
INSERT INTO `django_content_type` VALUES (8, 'app01', 'article2tag');
INSERT INTO `django_content_type` VALUES (9, 'app01', 'category');
INSERT INTO `django_content_type` VALUES (10, 'app01', 'comment');
INSERT INTO `django_content_type` VALUES (11, 'app01', 'site');
INSERT INTO `django_content_type` VALUES (12, 'app01', 'tag');
INSERT INTO `django_content_type` VALUES (13, 'app01', 'upanddown');
INSERT INTO `django_content_type` VALUES (6, 'app01', 'userinfo');
INSERT INTO `django_content_type` VALUES (3, 'auth', 'group');
INSERT INTO `django_content_type` VALUES (2, 'auth', 'permission');
INSERT INTO `django_content_type` VALUES (4, 'contenttypes', 'contenttype');
INSERT INTO `django_content_type` VALUES (5, 'sessions', 'session');

-- ----------------------------
-- Table structure for django_migrations
-- ----------------------------
DROP TABLE IF EXISTS `django_migrations`;
CREATE TABLE `django_migrations`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `app` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `applied` datetime(6) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 16 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of django_migrations
-- ----------------------------
INSERT INTO `django_migrations` VALUES (1, 'contenttypes', '0001_initial', '2019-09-26 11:17:37.037100');
INSERT INTO `django_migrations` VALUES (2, 'contenttypes', '0002_remove_content_type_name', '2019-09-26 11:17:37.648100');
INSERT INTO `django_migrations` VALUES (3, 'auth', '0001_initial', '2019-09-26 11:17:39.786100');
INSERT INTO `django_migrations` VALUES (4, 'auth', '0002_alter_permission_name_max_length', '2019-09-26 11:17:40.179100');
INSERT INTO `django_migrations` VALUES (5, 'auth', '0003_alter_user_email_max_length', '2019-09-26 11:17:40.210100');
INSERT INTO `django_migrations` VALUES (6, 'auth', '0004_alter_user_username_opts', '2019-09-26 11:17:40.237100');
INSERT INTO `django_migrations` VALUES (7, 'auth', '0005_alter_user_last_login_null', '2019-09-26 11:17:40.262100');
INSERT INTO `django_migrations` VALUES (8, 'auth', '0006_require_contenttypes_0002', '2019-09-26 11:17:40.286100');
INSERT INTO `django_migrations` VALUES (9, 'auth', '0007_alter_validators_add_error_messages', '2019-09-26 11:17:40.320100');
INSERT INTO `django_migrations` VALUES (10, 'auth', '0008_alter_user_username_max_length', '2019-09-26 11:17:40.351100');
INSERT INTO `django_migrations` VALUES (11, 'app01', '0001_initial', '2019-09-26 11:17:51.259100');
INSERT INTO `django_migrations` VALUES (12, 'admin', '0001_initial', '2019-09-26 11:17:52.602100');
INSERT INTO `django_migrations` VALUES (13, 'admin', '0002_logentry_remove_auto_add', '2019-09-26 11:17:52.665100');
INSERT INTO `django_migrations` VALUES (14, 'sessions', '0001_initial', '2019-09-26 11:17:53.077100');
INSERT INTO `django_migrations` VALUES (15, 'app01', '0002_auto_20190927_2338', '2019-09-27 15:38:21.149900');

-- ----------------------------
-- Table structure for django_session
-- ----------------------------
DROP TABLE IF EXISTS `django_session`;
CREATE TABLE `django_session`  (
  `session_key` varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `session_data` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `expire_date` datetime(6) NOT NULL,
  PRIMARY KEY (`session_key`) USING BTREE,
  INDEX `django_session_expire_date_a5c62663`(`expire_date`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- Records of django_session
-- ----------------------------
INSERT INTO `django_session` VALUES ('24u2yrmhdi531jov0bbd0dqiwsggm228', 'NmNlNDg3MTViNTRhMGQwMGQwOGU4OTI1Nzc0YjBiZDFmZWUzZmQ2ZTp7ImNvZGUiOiIxN1g2VSIsIl9hdXRoX3VzZXJfaWQiOiIzMSIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiY2Y1MTcyYTM2YWU2YmM0YjcyYzg2NTBlMmE4YmM2YTI0ZTcwNTZhOCJ9', '2019-10-21 08:46:17.722000');
INSERT INTO `django_session` VALUES ('fecdb61vj6tofk9assymxml68cyry5xt', 'NmEwZjcyNDJlNDNhY2IxZTlkNDgwMDY1MjY0M2U3ZDgyN2Y4YzI0Mzp7Il9hdXRoX3VzZXJfaWQiOiIzMSIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiY2Y1MTcyYTM2YWU2YmM0YjcyYzg2NTBlMmE4YmM2YTI0ZTcwNTZhOCIsImNvZGUiOiI0Q3ViNSJ9', '2019-10-12 07:24:25.576200');
INSERT INTO `django_session` VALUES ('rm1ll39yl65xghqd9v9rfcl1szc07iqh', 'MGE1MjdhMjRkNjk2NTA3NDhmNDE5MjI0YzljY2VmMTVhMjc2MDZjZDp7Il9hdXRoX3VzZXJfaWQiOiIzOSIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiYjU4Y2MwMzE1OTdjOGQxNjM4Y2ZhM2RiY2M5MzJlZjA2MDE3MGRiOSJ9', '2019-10-19 08:21:45.824200');
INSERT INTO `django_session` VALUES ('vlmtb4jo1gqkouvr0yzcb2jbw8c6zbcg', 'ZDgxMDIwMmE2MzIzOTYzNzZhYmNlNzcxMjAyYzZlYTYxZGY1NDgzMjp7ImNvZGUiOiI3YlFSUCIsIl9hdXRoX3VzZXJfaWQiOiIzMSIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiY2Y1MTcyYTM2YWU2YmM0YjcyYzg2NTBlMmE4YmM2YTI0ZTcwNTZhOCJ9', '2019-10-18 04:30:03.895800');
INSERT INTO `django_session` VALUES ('w8ko0zpzb1o6ax58bb1p7tvxoeog077l', 'NDA2ODVmODZjMWU3YjcwYzgyODdiNmQ3NTM3YjlmZjA4MWQxNzI0Nzp7ImNvZGUiOiI3SlNCUCIsIl9hdXRoX3VzZXJfaWQiOiIzMSIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiY2Y1MTcyYTM2YWU2YmM0YjcyYzg2NTBlMmE4YmM2YTI0ZTcwNTZhOCJ9', '2019-10-19 07:58:47.293200');

SET FOREIGN_KEY_CHECKS = 1;
